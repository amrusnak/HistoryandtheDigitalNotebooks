{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('population1.txt', sep=\"\\t\", header=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "head= pd.read_csv('population1.txt', sep=\"\\t\")\n",
    "head = head.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First</td>\n",
       "      <td>significant</td>\n",
       "      <td>FIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>census</td>\n",
       "      <td>change since</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1790</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1800</td>\n",
       "      <td>1820</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1880</td>\n",
       "      <td>1880</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 22   Unnamed: 23 Unnamed: 24\n",
       "0         NaN           NaN         NaN\n",
       "1         NaN            No         NaN\n",
       "2       First   significant        FIPS\n",
       "3     census   change since        code\n",
       "4         NaN           NaN         NaN\n",
       "5         NaN           NaN         NaN\n",
       "6        1790          1900         NaN\n",
       "7         NaN           NaN         NaN\n",
       "8        1800          1820          01\n",
       "9        1880          1880          02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head[['Unnamed: 22','Unnamed: 23','Unnamed: 24']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'Unnamed: 0':'state','Unnamed: 22': \"first_census\", 'Unnamed: 23': \"no_sig_change_since\", 'Unnamed: 24':'fips_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>1990</th>\n",
       "      <th>1980</th>\n",
       "      <th>1970</th>\n",
       "      <th>1960</th>\n",
       "      <th>1950</th>\n",
       "      <th>1940</th>\n",
       "      <th>1930</th>\n",
       "      <th>1920</th>\n",
       "      <th>1910</th>\n",
       "      <th>...</th>\n",
       "      <th>1850</th>\n",
       "      <th>1840</th>\n",
       "      <th>1830</th>\n",
       "      <th>1820</th>\n",
       "      <th>1810</th>\n",
       "      <th>1800</th>\n",
       "      <th>1790</th>\n",
       "      <th>first_census</th>\n",
       "      <th>no_sig_change_since</th>\n",
       "      <th>fips_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>248,709,873</td>\n",
       "      <td>226,545,805</td>\n",
       "      <td>203,211,926</td>\n",
       "      <td>179,323,175</td>\n",
       "      <td>151,325,798</td>\n",
       "      <td>132,164,569</td>\n",
       "      <td>123,202,624</td>\n",
       "      <td>106,021,537</td>\n",
       "      <td>92,228,496</td>\n",
       "      <td>...</td>\n",
       "      <td>23,191,876</td>\n",
       "      <td>17,063,353</td>\n",
       "      <td>12,860,702</td>\n",
       "      <td>9,638,453</td>\n",
       "      <td>7,239,881</td>\n",
       "      <td>5,308,483</td>\n",
       "      <td>3,929,214</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4,040,587</td>\n",
       "      <td>3,893,888</td>\n",
       "      <td>3,444,165</td>\n",
       "      <td>3,266,740</td>\n",
       "      <td>3,061,743</td>\n",
       "      <td>2,832,961</td>\n",
       "      <td>2,646,248</td>\n",
       "      <td>2,348,174</td>\n",
       "      <td>2,138,093</td>\n",
       "      <td>...</td>\n",
       "      <td>771,623</td>\n",
       "      <td>590,756</td>\n",
       "      <td>309,527</td>\n",
       "      <td>127,901</td>\n",
       "      <td>9,046</td>\n",
       "      <td>1,250</td>\n",
       "      <td>---</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>550,043</td>\n",
       "      <td>401,851</td>\n",
       "      <td>300,382</td>\n",
       "      <td>226,167</td>\n",
       "      <td>128,643</td>\n",
       "      <td>72,524</td>\n",
       "      <td>59,278</td>\n",
       "      <td>55,036</td>\n",
       "      <td>64,356</td>\n",
       "      <td>...</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           state         1990         1980         1970         1960  \\\n",
       "0            NaN          NaN          NaN          NaN          NaN   \n",
       "1  UNITED STATES  248,709,873  226,545,805  203,211,926  179,323,175   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3        Alabama    4,040,587    3,893,888    3,444,165    3,266,740   \n",
       "4         Alaska      550,043      401,851      300,382      226,167   \n",
       "\n",
       "          1950         1940         1930         1920        1910  ...  \\\n",
       "0          NaN          NaN          NaN          NaN         NaN  ...   \n",
       "1  151,325,798  132,164,569  123,202,624  106,021,537  92,228,496  ...   \n",
       "2          NaN          NaN          NaN          NaN         NaN  ...   \n",
       "3    3,061,743    2,832,961    2,646,248    2,348,174   2,138,093  ...   \n",
       "4      128,643       72,524       59,278       55,036      64,356  ...   \n",
       "\n",
       "         1850        1840        1830       1820       1810       1800  \\\n",
       "0         NaN         NaN         NaN        NaN        NaN        NaN   \n",
       "1  23,191,876  17,063,353  12,860,702  9,638,453  7,239,881  5,308,483   \n",
       "2         NaN         NaN         NaN        NaN        NaN        NaN   \n",
       "3     771,623     590,756     309,527    127,901      9,046      1,250   \n",
       "4        ---         ---         ---        ---        ---        ---    \n",
       "\n",
       "        1790 first_census no_sig_change_since fips_code  \n",
       "0        NaN          NaN                 NaN       NaN  \n",
       "1  3,929,214       1790.0              1900.0       NaN  \n",
       "2        NaN          NaN                 NaN       NaN  \n",
       "3       ---        1800.0              1820.0       1.0  \n",
       "4       ---        1880.0              1880.0       2.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', '1990', '1980', '1970', '1960', '1950', '1940', '1930', '1920',\n",
       "       '1910', '1900', '1890', '1880', '1870', '1860', '1850', '1840', '1830',\n",
       "       '1820', '1810', '1800', '1790', 'first_census', 'no_sig_change_since',\n",
       "       'fips_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['state','1870','1880','1890','1900']].dropna(axis=0).to_csv('states_population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_urban_lines(l):\n",
    "    result = []\n",
    "    \n",
    "    for x in l:\n",
    "        \n",
    "\n",
    "        try:\n",
    "#            x = x.replace('*','')\n",
    "            x = re.sub('\\.\\.+','---',x)\n",
    "\n",
    "\n",
    "            x = re.sub('\\-\\-+','', x)\n",
    "        \n",
    "            s = x.split('   ')\n",
    "            if len(s) == 3:\n",
    "                result.append(s[0:3])\n",
    "            elif len(s) == 6:\n",
    "                result.append(s[0:3])\n",
    "                result.append(s[3:6])\n",
    "            elif len(s) == 4:\n",
    "                result.append(s.remove(''))\n",
    "            elif len(s) == 2:\n",
    "                result.append(x.split('  '))\n",
    "                \n",
    "            else:\n",
    "#                pass\n",
    "                result.append((str(s), np.nan,np.nan))\n",
    "                \n",
    "        except:\n",
    "            result.append([x,'blank'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['1870', '1880','1890','1900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_ = []\n",
    "\n",
    "for year in years:\n",
    "    cities_raw = pd.read_csv('cities_{0}.txt'.format(year), sep=\"      \",header=4, engine='python')\n",
    "\n",
    "    try:\n",
    "        cities1 = cities_raw['Rank | Place']\n",
    "    except:\n",
    "        cities1 = cities_raw['Rank | Place 1/']\n",
    "\n",
    "    cities2 = cities_raw['Unnamed: 1']\n",
    "\n",
    "\n",
    "    cities1_list = cities1.dropna().tolist()\n",
    "    cities2_list = cities2.dropna().tolist()\n",
    "\n",
    "    cities_list = parse_urban_lines(cities1_list) + parse_urban_lines(cities2_list)\n",
    "    cities_.append(cities_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Population state                city\n",
      "0       942292    NY       New York city\n",
      "1       674022    PA   Philadelphia city\n",
      "2       396099    NY       Brooklyn city\n",
      "3       310864    MO      St. Louis city\n",
      "4       298977    IL        Chicago city\n",
      "..         ...   ...                 ...\n",
      "95       15389    GA        Augusta city\n",
      "96       15357    NY         Cohoes city\n",
      "97       15087    KY        Newport city\n",
      "98       15058    NJ  New Brunswick city\n",
      "99       14930    IA     Burlington city\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "    Population state               city\n",
      "0      1206299    NY      New York city\n",
      "1       847170    PA  Philadelphia city\n",
      "2       566663    NY      Brooklyn city\n",
      "3       503185    IL       Chicago city\n",
      "4       362839    MA        Boston city\n",
      "..         ...   ...                ...\n",
      "95       20550    TX   San Antonio city\n",
      "96       20541    NY        Elmira city\n",
      "97       20433    KY       Newport city\n",
      "98       20207    NY  Poughkeepsie city\n",
      "99       19743    IL   Springfield city\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "    Population state                city\n",
      "0      1515301    NY       New York city\n",
      "1      1099850    IL        Chicago city\n",
      "2      1046964    PA   Philadelphia city\n",
      "3       806343    NY       Brooklyn city\n",
      "4       451770    MO      St. Louis city\n",
      "..         ...   ...                 ...\n",
      "95       31494    IL         Quincy city\n",
      "96       31076    AL         Mobile city\n",
      "97       31007    KS         Topeka city\n",
      "98       30893    NY         Elmira city\n",
      "99       30801    MA          Salem city\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "    Population state                city\n",
      "0      3437202    NY       New York city\n",
      "1      1698575    IL        Chicago city\n",
      "2      1293697    PA   Philadelphia city\n",
      "3       575238    MO      St. Louis city\n",
      "4       560892    MA         Boston city\n",
      "..         ...   ...                 ...\n",
      "95       38973    PA        Altoona city\n",
      "96       38878    WV       Wheeling city\n",
      "97       38469    AL         Mobile city\n",
      "98       38415    AL     Birmingham city\n",
      "99       38307    AR    Little Rock city\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "cities_dict = {}\n",
    "    \n",
    "for i in range(len(years)):\n",
    "    year = years[i]\n",
    "    cities_list = cities_[i]\n",
    "    cities = pd.DataFrame(cities_list, columns=['rank','region','Population'])\n",
    "    cities = cities.dropna(axis=0)\n",
    "    \n",
    "    cities['state'] = cities.region.apply(lambda x:re.findall('\\s[A-Z][A-Z]\\s*',x)[0].strip())\n",
    "    cities['city'] = cities.region.apply(lambda x: x.split(re.findall('\\s[A-Z][A-Z]\\s*',x)[0])[0].strip(','))\n",
    "\n",
    "    \n",
    "    cities['Population'] = cities.Population.apply(lambda x: int(''.join(x.split(','))))\n",
    "    cities = cities.sort_values(by='Population', ascending=False)\n",
    "    cities = cities.reset_index()\n",
    "    cities = cities.drop('index',axis=1)\n",
    "    cities = cities.drop(['rank','region'], axis=1)\n",
    "    \n",
    "    print(cities)\n",
    "    cities_dict[year] = cities\n",
    "    cities.to_csv('cities_population_{0}.csv'.format(year))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
